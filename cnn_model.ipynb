{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dropout, Dense\n",
    "from mnist import MNIST\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run once to download data\n",
    "#Source for dataset: https://www.nist.gov/node/1298471/emnist-dataset\n",
    "\n",
    "# !wget https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip\n",
    "# !unzip gzip.zip #use Expand-Archive -Path \"your_archive.zip\" -DestinationPath \"destination_folder\" in windows\n",
    "# !rm gzip.zip #use del in windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the entire EMNIST dataset as numpy arrays\n",
    "emnist_data = MNIST(path='gzip', return_type='numpy')\n",
    "emnist_data.select_emnist('byclass')\n",
    "X_train, y_train = emnist_data.load_training()\n",
    "X_test, y_test = emnist_data.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dimension = 28\n",
    "# Reshape tensors to [n, y, x, 1] and normalize the pixel values between [0, 1]\n",
    "x_train = X_train.reshape(-1, img_dimension, img_dimension, 1).astype('float32') / 255.0\n",
    "x_test = X_test.reshape(-1, img_dimension, img_dimension, 1).astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of classes\n",
    "unique_classes = np.unique(y_train)\n",
    "num_classes = len(unique_classes)\n",
    "\n",
    "input_shape = (img_dimension, img_dimension, 1)\n",
    "\n",
    "# weight the classes (to combat the imbalance)\n",
    "class_weights = dict(enumerate(compute_class_weight(class_weight='balanced', classes=unique_classes, y=y_train)))\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model\n",
    "kernel_size = (5, 5)\n",
    "def createmodel():\n",
    "    return Sequential([\n",
    "        Convolution2D(16, kernel_size=kernel_size, padding='same', input_shape=input_shape, activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Convolution2D(32, kernel_size=kernel_size, padding='same', activation= 'relu'), #strides=2,\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Convolution2D(64, kernel_size=kernel_size, padding='same', activation= 'relu'),\n",
    "        MaxPooling2D(pool_size =(2,2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(num_classes, activation='softmax'),\n",
    "    ])\n",
    "#creating and compiling model\n",
    "model = createmodel()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model (Takes a few hours to train)\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    restore_best_weights=True)\n",
    "model.fit(x_train, y_train,\n",
    "          #class_weight=class_weights,\n",
    "          batch_size=10000,\n",
    "          epochs=200,\n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "def plotres(x, metric):\n",
    "    plt.plot(x[metric])\n",
    "    plt.plot(x['val_'+metric])\n",
    "    plt.title(metric.upper())\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "\n",
    "plotres(model.history.history, \"accuracy\")\n",
    "plotres(model.history.history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "model.save('letter_classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
